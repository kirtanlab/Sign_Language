{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import multiprocessing\n",
    "import argparse\n",
    "import os.path\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_landmarks(landmarks):\n",
    "    x_list, y_list = [], []\n",
    "    for landmark in landmarks.landmark:\n",
    "        x_list.append(landmark.x)\n",
    "        y_list.append(landmark.y)\n",
    "    return x_list, y_list\n",
    "\n",
    "\n",
    "def process_hand_keypoints(results):\n",
    "    hand1_x, hand1_y, hand2_x, hand2_y = [], [], [], []\n",
    "\n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        if len(results.multi_hand_landmarks) > 0:\n",
    "            hand1 = results.multi_hand_landmarks[0]\n",
    "            hand1_x, hand1_y = process_landmarks(hand1)\n",
    "\n",
    "        if len(results.multi_hand_landmarks) > 1:\n",
    "            hand2 = results.multi_hand_landmarks[1]\n",
    "            hand2_x, hand2_y = process_landmarks(hand2)\n",
    "\n",
    "    return hand1_x, hand1_y, hand2_x, hand2_y\n",
    "\n",
    "\n",
    "def process_pose_keypoints(results):\n",
    "    pose = results.pose_landmarks\n",
    "    pose_x, pose_y = process_landmarks(pose)\n",
    "    return pose_x, pose_y\n",
    "\n",
    "\n",
    "def swap_hands(left_wrist, right_wrist, hand, input_hand):\n",
    "    left_wrist_x, left_wrist_y = left_wrist\n",
    "    right_wrist_x, right_wrist_y = right_wrist\n",
    "    hand_x, hand_y = hand\n",
    "\n",
    "    left_dist = (left_wrist_x - hand_x) ** 2 + (left_wrist_y - hand_y) ** 2\n",
    "    right_dist = (right_wrist_x - hand_x) ** 2 + (right_wrist_y - hand_y) ** 2\n",
    "\n",
    "    if left_dist < right_dist and input_hand == \"h2\":\n",
    "        return True\n",
    "\n",
    "    if right_dist < left_dist and input_hand == \"h1\":\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(path, save_dir):\n",
    "    hands = mp.solutions.hands.Hands(\n",
    "        min_detection_confidence=0.5, min_tracking_confidence=0.5\n",
    "    )\n",
    "    pose = mp.solutions.pose.Pose(\n",
    "        min_detection_confidence=0.5, min_tracking_confidence=0.5,\n",
    "    )\n",
    "\n",
    "    pose_points_x, pose_points_y = [], []\n",
    "    hand1_points_x, hand1_points_y = [], []\n",
    "    hand2_points_x, hand2_points_y = [], []\n",
    "\n",
    "    label = path.split(\"/\")[-2]\n",
    "    label = \"\".join([i for i in label if i.isalpha()]).lower()\n",
    "    uid = os.path.splitext(os.path.basename(path))[0]\n",
    "    uid = \"_\".join([label, uid])\n",
    "    n_frames = 0\n",
    "    if not os.path.isfile(path):\n",
    "        warnings.warn(path + \" file not found\")\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        hand_results = hands.process(image)\n",
    "        pose_results = pose.process(image)\n",
    "\n",
    "          ##Adding for Nonetype Objects\n",
    "        if pose_results is None or pose_results.pose_landmarks is None:\n",
    "            print('path',path)\n",
    "            continue\n",
    "\n",
    "        hand1_x, hand1_y, hand2_x, hand2_y = process_hand_keypoints(hand_results)\n",
    "        pose_x, pose_y = process_pose_keypoints(pose_results)\n",
    "\n",
    "        ## Assign hands to correct positions\n",
    "        if len(hand1_x) > 0 and len(hand2_x) == 0:\n",
    "            if swap_hands(\n",
    "                left_wrist=(pose_x[15], pose_y[15]),\n",
    "                right_wrist=(pose_x[16], pose_y[16]),\n",
    "                hand=(hand1_x[0], hand1_y[0]),\n",
    "                input_hand=\"h1\",\n",
    "            ):\n",
    "                hand1_x, hand1_y, hand2_x, hand2_y = hand2_x, hand2_y, hand1_x, hand1_y\n",
    "\n",
    "        elif len(hand1_x) == 0 and len(hand2_x) > 0:\n",
    "            if swap_hands(\n",
    "                left_wrist=(pose_x[15], pose_y[15]),\n",
    "                right_wrist=(pose_x[16], pose_y[16]),\n",
    "                hand=(hand2_x[0], hand2_y[0]),\n",
    "                input_hand=\"h2\",\n",
    "            ):\n",
    "                hand1_x, hand1_y, hand2_x, hand2_y = hand2_x, hand2_y, hand1_x, hand1_y\n",
    "\n",
    "        ## Set to nan so that values can be interpolated in dataloader\n",
    "        pose_x = pose_x[:25] if pose_x else [np.nan] * 25\n",
    "        pose_y = pose_y[:25] if pose_y else [np.nan] * 25\n",
    "\n",
    "        hand1_x = hand1_x if hand1_x else [np.nan] * 21\n",
    "        hand1_y = hand1_y if hand1_y else [np.nan] * 21\n",
    "        hand2_x = hand2_x if hand2_x else [np.nan] * 21\n",
    "        hand2_y = hand2_y if hand2_y else [np.nan] * 21\n",
    "\n",
    "        pose_points_x.append(pose_x)\n",
    "        pose_points_y.append(pose_y)\n",
    "        hand1_points_x.append(hand1_x)\n",
    "        hand1_points_y.append(hand1_y)\n",
    "        hand2_points_x.append(hand2_x)\n",
    "        hand2_points_y.append(hand2_y)\n",
    "\n",
    "        n_frames += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    ## Set to nan so that values can be interpolated in dataloader\n",
    "    pose_points_x = pose_points_x if pose_points_x else [[np.nan] * 25]\n",
    "    pose_points_y = pose_points_y if pose_points_y else [[np.nan] * 25]\n",
    "\n",
    "    hand1_points_x = hand1_points_x if hand1_points_x else [[np.nan] * 21]\n",
    "    hand1_points_y = hand1_points_y if hand1_points_y else [[np.nan] * 21]\n",
    "    hand2_points_x = hand2_points_x if hand2_points_x else [[np.nan] * 21]\n",
    "    hand2_points_y = hand2_points_y if hand2_points_y else [[np.nan] * 21]\n",
    "\n",
    "    save_data = {\n",
    "        \"uid\": uid,\n",
    "        \"label\": label,\n",
    "        \"pose_x\": pose_points_x,\n",
    "        \"pose_y\": pose_points_y,\n",
    "        \"hand1_x\": hand1_points_x,\n",
    "        \"hand1_y\": hand1_points_y,\n",
    "        \"hand2_x\": hand2_points_x,\n",
    "        \"hand2_y\": hand2_points_y,\n",
    "        \"n_frames\": n_frames,\n",
    "    }\n",
    "    with open(os.path.join(save_dir, f\"{uid}.json\"), \"w\") as f:\n",
    "        json.dump(save_data, f)\n",
    "\n",
    "    hands.close()\n",
    "    pose.close()\n",
    "    del hands, pose, save_data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path, include_dir):\n",
    "    with open(path, \"r\") as fp:\n",
    "        data = fp.read()\n",
    "        data = data.split(\"\\n\")\n",
    "    data = list(map(lambda x: os.path.join(include_dir, x), data))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_train_test_val_paths(train_test_paths):\n",
    "    train_paths = load_file(\n",
    "        f\"{train_test_paths}/temp_include_train.txt\", '/home/kirtan/Documents/Sign_Language/data'\n",
    "    )\n",
    "    val_paths = load_file(f\"{train_test_paths}/temp_include_val.txt\", \"/home/kirtan/Documents/Sign_Language/data\")\n",
    "    test_paths = load_file(\n",
    "        f\"{train_test_paths}/temp_include_test.txt\", \"/home/kirtan/Documents/Sign_Language/data/\"\n",
    "    )\n",
    "    return train_paths, val_paths, test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keypoints(dataset,save_dir, file_paths, mode,n_cores):\n",
    "    save_dir = os.path.join(save_dir, f\"{dataset}_{mode}_keypoints\")\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)    \n",
    "    for path in tqdm(file_paths, desc=f\"processing {mode} videos\"):\n",
    "        (process_video)(path, save_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "file_path = '/home/kirtan/Documents/Sign_Language/train_test_split'\n",
    "train_paths, val_paths, test_paths = load_train_test_val_paths(file_path)\n",
    "# save_keypoints('temp_include','/home/kirtan/Documents/Sign_Language/keypoints', val_paths, \"val\",n_cores)\n",
    "# save_keypoints('temp_include', '/home/kirtan/Documents/Sign_Language/keypoints',test_paths, \"test\",n_cores)\n",
    "save_keypoints('temp_include', '/home/kirtan/Documents/Sign_Language/keypoints',train_paths, \"train\",n_cores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

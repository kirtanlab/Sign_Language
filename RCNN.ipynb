{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "# from tools import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResCRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResCRNN, self).__init__()\n",
    "        self.batch_size = 8\n",
    "        self.seq_length = 80\n",
    "        self.num_classes = 59\n",
    "        self.lstm_hidden_size = 512\n",
    "        self.lstm_num_layers = 1\n",
    "        self.attention = 0\n",
    "\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1] #removing Linear(in_features=2048, out_features=1000, bias=True) layer\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=resnet.fc.in_features,\n",
    "            hidden_size=self.lstm_hidden_size,\n",
    "            num_layers=self.lstm_num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(self.lstm_hidden_size, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # CNN\n",
    "        cnn_embed_seq = []\n",
    "        # x: (batch_size, channel, t, h, w)\n",
    "#         print('x',x)\n",
    "        for t in range(x.size(2)):\n",
    "#             print('x.size(2): t',x.size(2),t)\n",
    "            # with torch.no_grad():\n",
    "            out = self.resnet(x[:, :, t, :, :])\n",
    "#             print('inside loop',out.shape)\n",
    "            # print(out.shape)\n",
    "            out = out.view(out.size(0), -1)\n",
    "#             print('inside after loop',out.shape)\n",
    "            cnn_embed_seq.append(out)\n",
    "\n",
    "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0)\n",
    "        cnn_embed_seq = cnn_embed_seq.transpose_(0, 1)\n",
    "        # LSTM\n",
    "        # use faster code paths\n",
    "        self.lstm.flatten_parameters()\n",
    "        out, (h_n, c_n) = self.lstm(cnn_embed_seq, None)\n",
    "#         print('afte lstm',out.shape)\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "#         print('output shape',out.shape)\n",
    "        return out     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn = ResCRNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameDir_path = '/home/kirtan/Documents/Sign_Language/data/Frames/'\n",
    "checkpoint_path = '/home/kirtan/Documents/Sign_Language/'\n",
    "log_path = '/home/kirtan/Documents/Sign_Language/cnnlstm_{:%Y-%m-%d_%H-%M-%S}'.format(datetime.now())\n",
    "sum_path = '/home/kirtan/Documents/Sign_Language/sum_cnnlstm_{:%Y-%m-%d_%H-%M-%S}'.format(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "    return json_file\n",
    "label_map = load_json('./label_map_temp_include.json')\n",
    "print(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "filenames_train = []\n",
    "masks_train =[]\n",
    "labels_test = []\n",
    "filenames_test = []\n",
    "masks_test =[]\n",
    "labels_val = []\n",
    "filenames_val = []\n",
    "masks_val =[]\n",
    "seq_length=80\n",
    "def get_Lables(mode):\n",
    "    train_label = []\n",
    "    train_filename = []\n",
    "    train_mask=[]\n",
    "    train_split_file = f'./train_test_split/temp_include_{mode}.txt'\n",
    "    train_file = open(train_split_file, 'r')\n",
    "    for line in train_file:\n",
    "        label = \"\".join([i for i in line if i.isalpha()]).lower()\n",
    "        label = label[10:]\n",
    "        label = label[:-6]\n",
    "        line = line.split(\"/\")\n",
    "        line.pop(1)\n",
    "        line.insert(1,label)\n",
    "        last_word = line[-1].strip('\\n')\n",
    "        last_word = last_word + \"_frames\"\n",
    "        line[-1] = last_word\n",
    "        line = \"/\".join(line)\n",
    "        line = frameDir_path + line #frame folder\n",
    "        frame_names = os.listdir(line)\n",
    "        frame_names = natsort.natsorted(frame_names)\n",
    "        orginal_length = len(frame_names)\n",
    "        padding_length = seq_length - orginal_length\n",
    "        for i in range(orginal_length):\n",
    "            temp_fileName= os.path.join(line, frame_names[i])\n",
    "            train_filename.append(temp_fileName)\n",
    "        train_filename = train_filename + [\"\"] * padding_length\n",
    "    for frame in train_filename:\n",
    "        if frame != \"\":\n",
    "            split_frame = frame.split(\"/\")\n",
    "            train_label.append(split_frame[-3])\n",
    "            train_mask.append(True)  # Valid element, set mask to True\n",
    "        else:\n",
    "            train_label.append(4)\n",
    "            train_mask.append(False)  # Padded element, set mask to False\n",
    "    for i in range(len(train_label)):\n",
    "        if train_label[i] != 4:\n",
    "            train_label[i] = label_map[train_label[i]]\n",
    "    train_file.close()\n",
    "    return np.array(train_filename),np.array(train_label),np.array(train_mask)\n",
    "\n",
    "filenames_train,labels_train,masks_train = get_Lables('train')\n",
    "filenames_val,labels_val,masks_val = get_Lables('val')\n",
    "filenames_test,labels_test,masks_test = get_Lables('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('filenames_train.shape',filenames_train.shape)\n",
    "print(\"labels_train.shape\",labels_train.shape)\n",
    "print(\"masks_train.shape\",masks_train.shape)\n",
    "print(\"filenames_test.shape\",filenames_test.shape)\n",
    "print(\"labels_test.shape\",labels_test.shape)\n",
    "print(\"masks_test.shape\",masks_test.shape)\n",
    "print(\"filenames_val.shape\",filenames_val.shape)\n",
    "print(\"labels_val.shape\",labels_val.shape)\n",
    "print(\"masks_val.shape\",masks_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels,mode):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.image_paths)//80)\n",
    "\n",
    "    def preprocess_function(self,filename,mode):\n",
    "        if filename != \"\":\n",
    "            image = Image.open(filename)\n",
    "        else:\n",
    "            image = Image.fromarray(np.zeros((64, 64, 3), dtype=np.uint8))\n",
    "        \n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = image.to(torch.float32)\n",
    "        image = transforms.Resize((64, 64))(image)\n",
    "        \n",
    "        if mode != 'Test':\n",
    "            image = transforms.RandomHorizontalFlip()(image)\n",
    "            image = transforms.RandomRotation(90)(image)\n",
    "            image = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)(image)\n",
    "            image = transforms.Normalize(mean=[0.5], std=[0.5])(image)\n",
    "    \n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # total 80 consicutive frames\n",
    "        lower_value = idx * 80 \n",
    "        upper_value = idx * 80 + 79\n",
    "\n",
    "        filenames_range = self.image_paths[lower_value:upper_value+1]  #list of frames, +1 since slice excludes uppervalue \n",
    "        label_value = self.labels[lower_value] # constant value of label \n",
    "\n",
    "\n",
    "        processed_images = [self.preprocess_function(image,self.mode) for image in filenames_range]\n",
    "        image_tensor = torch.stack(processed_images,dim=0)\n",
    "\n",
    "        self.images = image_tensor.permute(1, 0, 2, 3)\n",
    "\n",
    "        label = torch.nn.functional.one_hot(torch.tensor(label_value), num_classes=59)\n",
    "\n",
    "        label = label.type(torch.long)\n",
    "\n",
    "        return {'data': self.images, 'label': label}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(filenames_train, labels_train,mode=\"train\")\n",
    "test_dataset = CustomDataset(filenames_test, labels_test,mode=\"Test\")\n",
    "val_dataset = CustomDataset(filenames_val, labels_val,mode=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dataset[72*8]['data'].shape)\n",
    "# print(len(train_dataset[72*8]['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size=8, shuffle=False,drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=8, shuffle=False,drop_last=True)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=8,shuffle=False,drop_last=True)\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader)) # 46078(Total Frames) / 640(batch_size*(seq_length)) = 72(Total Batches)\n",
    "# print(batch['label'])\n",
    "# print(batch['data'].shape)\n",
    "# print(len(batch['data'])) # 8 number of videos = batch size , total number of batchs = len(train_dataloader) , batchsize * total number of batches = total number of samples(videos) = 72*8 = 576\n",
    "# print(len(batch['label'])) # per batch 8 videos -> 8 labels each -> len(batch['label]) === 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    count = 0\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        losses= []\n",
    "        orgs =[]\n",
    "        outs = []\n",
    "        print(\"Training\")\n",
    "        progress_bar = tqdm(train_loader, ncols=80)\n",
    "        for batch_idx, data in enumerate(progress_bar):\n",
    "                inputs, labels = data['data'].to(device), data['label'].to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                org = torch.argmax(labels, dim=1)\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                orgs.append(org)\n",
    "                outs.append(outputs)\n",
    "\n",
    "                org = org.float()\n",
    "                outputs = outputs.float()\n",
    "\n",
    "                org.requires_grad = True\n",
    "                outputs.requires_grad = True\n",
    "\n",
    "                loss = criterion(outputs, org)\n",
    "                temp_loss = loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                score = accuracy_score(org.detach().numpy(), outputs.detach().numpy())\n",
    "                # Calculate precision\n",
    "                precision = precision_score(org.detach().numpy(), outputs.detach().numpy(), average='micro')\n",
    "\n",
    "                # Calculate recall\n",
    "                recall = recall_score(org.detach().numpy(), outputs.detach().numpy(), average='micro')\n",
    "\n",
    "                # Calculate F1-score\n",
    "                f1 = f1_score(org.detach().numpy(), outputs.detach().numpy(), average='micro')\n",
    "\n",
    "                print('Training Loss: '+ str(temp_loss.item()) + 'Training Accuracy: ' + str (100.0 * score),'Training precision: '+ str(100.0 * precision)+'Training recall: '+ str(100.0 * recall)+'Training f1_score: '+str(100 * f1))\n",
    "        \n",
    "        training_loss = sum(losses)/len(losses)\n",
    "        orgs = torch.stack(orgs, dim=0)\n",
    "        outs = torch.stack(outs, dim=0)\n",
    "#         print(orgs,outs)\n",
    "        training_acc = accuracy_score(orgs.flatten(), outs.flatten())\n",
    "        training_precision =precision_score(orgs.flatten(),outs.flatten(),average='micro')\n",
    "        training_recall = recall_score(orgs.flatten(),outs.flatten(),average='micro')\n",
    "        training_f1 = f1_score(orgs.flatten(),outs.flatten(),average='micro')\n",
    "        print('\\nAvg.Training Accuracy: ',training_acc,' Avg.Training Loss: ',training_loss,' Avg.Training Precision: ', training_precision,' Avg.Training Recall: ',training_recall,\" Avg.Training f1_score: \",training_f1)\n",
    "        \n",
    "        print(\"\\nValidation\")\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses=[]\n",
    "        val_orgs =[]\n",
    "        val_outs = []\n",
    "        val_progress_bar = tqdm(val_loader, ncols=80)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(val_progress_bar):\n",
    "                inputs, labels = data['data'].to(device), data['label'].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                org = torch.argmax(labels, dim=1)\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                val_orgs.append(org)\n",
    "                val_outs.append(outputs)\n",
    "\n",
    "                org = org.float()\n",
    "                outputs = outputs.float()\n",
    "                \n",
    "                loss = criterion(outputs, org)\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "                score = accuracy_score(org.detach().numpy(), outputs.detach().numpy())\n",
    "                # Calculate precision\n",
    "                precision = precision_score(org.detach().numpy(), outputs.detach().numpy(), average='micro')\n",
    "\n",
    "                # Calculate recall\n",
    "                recall = recall_score(org.detach().numpy(), outputs.detach().numpy(), average='micro')\n",
    "\n",
    "                # Calculate F1-score\n",
    "                f1 = f1_score(org.detach().numpy(), outputs.detach().numpy(), average='micro')\n",
    "\n",
    "                print('Val Loss: '+ str(temp_loss.item()) + 'Val Accuracy: ' + str (100.0 * score),'Val precision: '+ str(100.0 * precision)+'Val recall: '+ str(100.0 * recall)+'Val f1_score: '+str(100 * f1))\n",
    "#                 progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': 100.0 * score})\n",
    "        \n",
    "        validation_loss = sum(val_losses)/len(val_losses)\n",
    "        val_orgs = torch.stack(val_orgs, dim=0)\n",
    "        val_outs = torch.stack(val_outs, dim=0)\n",
    "        val_acc = accuracy_score(val_orgs.flatten(), val_outs.flatten())\n",
    "        val_precision =precision_score(val_orgs.flatten(),val_outs.flatten(),average='micro')\n",
    "        val_recall = recall_score(val_orgs.flatten(),val_outs.flatten(),average='micro')\n",
    "        val_f1 = f1_score(val_orgs.flatten(),val_outs.flatten(),average='micro')\n",
    "        print('\\nAvg.Val Accuracy: ',val_acc,' Avg.Val Loss: ',validation_loss,' Avg. Val: ', val_precision,' Avg. Val: ',val_recall,\" Avg. Val: \",val_f1)\n",
    "        \n",
    "\n",
    "#         # Print training and validation statistics for the current epoch\n",
    "#         print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "#         print(f\"\\nTrain Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
    "#         print(f\"\\nVal Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%\")\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_path, \"slr_convlstm_epoch{:03d}.pth\".format(epoch+1)))\n",
    "#         logger.info(\"Epoch {} Model Saved\".format(epoch+1).center(60, '#'))\n",
    "\n",
    "\n",
    "model = ResCRNN()\n",
    "\n",
    "train(model, train_dataloader, val_dataloader, num_epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keypoints_dir,\n",
    "        use_augs,\n",
    "        label_map,\n",
    "        mode=\"train\",\n",
    "        max_frame_len=200,\n",
    "        frame_length=1080,\n",
    "        frame_width=1920,\n",
    "    ):\n",
    "        self.files = sorted(glob.glob(os.path.join(keypoints_dir, \"*.json\")))\n",
    "        self.mode = mode\n",
    "        self.use_augs = use_augs\n",
    "        self.label_map = label_map\n",
    "        self.max_frame_len = max_frame_len\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_width = frame_width\n",
    "\n",
    "        # self.augs = [\n",
    "        #     Augmentation(OneOf(plus7rotation, minus7rotation), p=0.4),\n",
    "        #     Augmentation(gaussSample, p=0.4),\n",
    "        #     Augmentation(cutout, p=0.4),\n",
    "        #     Augmentation(OneOf(upsample, downsample), p=0.4),\n",
    "        # ]\n",
    "\n",
    "    # def augment(self, df):\n",
    "    #     for aug in self.augs:\n",
    "    #         df = aug(df)\n",
    "    #     return df\n",
    "    def interpolate(self, arr):\n",
    "\n",
    "        arr_x = arr[:, :, 0]\n",
    "        arr_x = pd.DataFrame(arr_x)\n",
    "        arr_x = arr_x.interpolate(method=\"linear\", limit_direction=\"both\").to_numpy()\n",
    "\n",
    "        arr_y = arr[:, :, 1]\n",
    "        arr_y = pd.DataFrame(arr_y)\n",
    "        arr_y = arr_y.interpolate(method=\"linear\", limit_direction=\"both\").to_numpy()\n",
    "\n",
    "        if np.count_nonzero(~np.isnan(arr_x)) == 0:\n",
    "            arr_x = np.zeros(arr_x.shape)\n",
    "        if np.count_nonzero(~np.isnan(arr_y)) == 0:\n",
    "            arr_y = np.zeros(arr_y.shape)\n",
    "\n",
    "        arr_x = arr_x * self.frame_width\n",
    "        arr_y = arr_y * self.frame_length\n",
    "\n",
    "        return np.stack([arr_x, arr_y], axis=-1)\n",
    "\n",
    "    def combine_xy(self, x, y):\n",
    "        x, y = np.array(x), np.array(y)\n",
    "        _, length = x.shape\n",
    "        x = x.reshape((-1, length, 1))\n",
    "        y = y.reshape((-1, length, 1))\n",
    "        return np.concatenate((x, y), -1).astype(np.float32)\n",
    "    def interpolate(self, arr):\n",
    "\n",
    "        arr_x = arr[:, :, 0]\n",
    "        arr_x = pd.DataFrame(arr_x)\n",
    "        arr_x = arr_x.interpolate(method=\"linear\", limit_direction=\"both\").to_numpy()\n",
    "\n",
    "        arr_y = arr[:, :, 1]\n",
    "        arr_y = pd.DataFrame(arr_y)\n",
    "        arr_y = arr_y.interpolate(method=\"linear\", limit_direction=\"both\").to_numpy()\n",
    "\n",
    "        if np.count_nonzero(~np.isnan(arr_x)) == 0:\n",
    "            arr_x = np.zeros(arr_x.shape)\n",
    "        if np.count_nonzero(~np.isnan(arr_y)) == 0:\n",
    "            arr_y = np.zeros(arr_y.shape)\n",
    "\n",
    "        arr_x = arr_x * self.frame_width\n",
    "        arr_y = arr_y * self.frame_length\n",
    "\n",
    "        return np.stack([arr_x, arr_y], axis=-1)\n",
    "\n",
    "    def combine_xy(self, x, y):\n",
    "        x, y = np.array(x), np.array(y)\n",
    "        _, length = x.shape\n",
    "        x = x.reshape((-1, length, 1))\n",
    "        y = y.reshape((-1, length, 1))\n",
    "        return np.concatenate((x, y), -1).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        row = pd.read_json(file_path, typ=\"series\")\n",
    "        label = row.label\n",
    "        label = \"\".join([i for i in label if i.isalpha()]).lower()\n",
    "\n",
    "        pose = self.combine_xy(row.pose_x, row.pose_y)\n",
    "        h1 = self.combine_xy(row.hand1_x, row.hand1_y)\n",
    "        h2 = self.combine_xy(row.hand2_x, row.hand2_y)\n",
    "\n",
    "        pose = self.interpolate(pose)\n",
    "        h1 = self.interpolate(h1)\n",
    "        h2 = self.interpolate(h2)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"uid\": row.uid,\n",
    "                \"pose\": pose.tolist(),\n",
    "                \"hand1\": h1.tolist(),\n",
    "                \"hand2\": h2.tolist(),\n",
    "                \"label\": label,\n",
    "            }\n",
    "        )\n",
    "        if self.mode == \"train\" and self.use_augs:\n",
    "            df = self.augment(df)\n",
    "\n",
    "        pose = (\n",
    "            np.array(list(map(np.array, df.pose.values)))\n",
    "            .reshape(-1, 50)\n",
    "            .astype(np.float32)\n",
    "        )\n",
    "        h1 = (\n",
    "            np.array(list(map(np.array, df.hand1.values)))\n",
    "            .reshape(-1, 42)\n",
    "            .astype(np.float32)\n",
    "        )\n",
    "        h2 = (\n",
    "            np.array(list(map(np.array, df.hand2.values)))\n",
    "            .reshape(-1, 42)\n",
    "            .astype(np.float32)\n",
    "        )\n",
    "        final_data = np.concatenate((pose, h1, h2), -1)\n",
    "        final_data = np.pad(\n",
    "            final_data,\n",
    "            ((0, self.max_frame_len - final_data.shape[0]), (0, 0)),\n",
    "            \"constant\",\n",
    "        )\n",
    "        return {\n",
    "            \"uid\": row.uid,\n",
    "            \"data\": torch.FloatTensor(final_data),\n",
    "            \"label\": self.label_map[label],\n",
    "            \"lablel_string\": label,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "    return json_file\n",
    "def load_label_map(dataset):\n",
    "    file_path = f\"label_maps/label_map_{dataset}.json\"\n",
    "    return load_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'label_maps/label_map_temp_include.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m KeypointsDataset(\n\u001b[1;32m      2\u001b[0m             keypoints_dir\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m/home/kirtan/Documents/Sign_Language/keypoints/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtemp_include_test_keypoints\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m             use_augs\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m----> 4\u001b[0m             label_map\u001b[39m=\u001b[39mload_label_map(\u001b[39m\"\u001b[39;49m\u001b[39mtemp_include\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      5\u001b[0m             mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             max_frame_len\u001b[39m=\u001b[39m\u001b[39m169\u001b[39m,\n\u001b[1;32m      7\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mload_label_map\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_label_map\u001b[39m(dataset):\n\u001b[1;32m      6\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlabel_maps/label_map_\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mreturn\u001b[39;00m load_json(file_path)\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mload_json\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_json\u001b[39m(path):\n\u001b[0;32m----> 2\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         json_file \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m json_file\n",
      "File \u001b[0;32m~/.conda/envs/crossway/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'label_maps/label_map_temp_include.json'"
     ]
    }
   ],
   "source": [
    "dataset = KeypointsDataset(\n",
    "            keypoints_dir=os.path.join(\"/home/kirtan/Documents/Sign_Language/keypoints/\", f\"temp_include_test_keypoints\"),\n",
    "            use_augs=False,\n",
    "            label_map=load_label_map(\"temp_include\"),\n",
    "            mode=\"test\",\n",
    "            max_frame_len=169,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crossway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
